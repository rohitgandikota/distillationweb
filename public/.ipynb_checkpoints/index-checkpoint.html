<!doctype html>
<html lang="en">
<head>
<title>Distilling Diversity and Control in Diffusion Models</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<meta name="description" content="Improving diversity in distilled diffusion models through strategic use of base models and introducing DT-Visualization." />
<meta property="og:title" content="Distilling Diversity and Control in Diffusion Models" />
<meta property="og:description" content="Improving diversity in distilled diffusion models through strategic use of base models and introducing DT-Visualization." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="twitter:title" content="Distilling Diversity and Control in Diffusion Models" />
<meta name="twitter:description" content="Improving diversity in distilled diffusion models through strategic use of base models and introducing DT-Visualization." />
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<style>
.relatedthumb {
  float:left; width: 200px; margin: 3px 10px 7px 0;
}
.relatedblock {
  clear: both;
  display: inline-block;
}
.bold-sc {
  font-variant: small-caps;
  font-weight: bold;
}
.cite, .citegroup {
  margin-bottom: 8px;
}
:target {
  background-color: yellow;
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 Distilling
 <nobr class="widenobr">Diversity and Control</nobr>
 in 
 <nobr class="widenobr">Diffusion Models</nobr>
 </h1>
<address>
  <nobr><a href="https://rohitgandikota.github.io/" target="_blank">Rohit Gandikota</a><sup>1</sup>,</nobr>
  <nobr><a href="https://baulab.info/" target="_blank">David Bau</a><sup>1</sup></nobr>
 <br>
  <nobr><sup>1</sup><a href="https://khoury.northeastern.edu/" target="_blank">Northeastern University</a></nobr>
</address>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row justify-content-center text-center">

<p>
<a href="https://arxiv.org/pdf/XXXX.XXXXX.pdf" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid; margin: 0 38px;" alt="ArXiv Preprint thumbnail" data-nothumb=""><br>ArXiv<br>Preprint</a>
<a href="https://github.com/rohitgandikota/distillation" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Github code thumbnail" data-nothumb=""><br>Source Code<br>Github</a>
</p>

<div class="card" style="max-width: 1020px;">
<div class="card-block">
<h3>How can we restore diversity in distilled diffusion models?</h3>
<p>
Distilled diffusion models generate images in far fewer timesteps but suffer from a critical limitation: reduced sample diversity compared to their base model counterparts.
</p>
<p>
In this paper, we introduce two key innovations:
<ul style="text-align: left;">
  <li><b>DT-Visualization</b> (Diffusion Target): A novel analysis and debugging technique that reveals what a diffusion model "thinks" the final image will be at any intermediate timestep</li>
  <li><b>Diversity Distillation</b>: A hybrid inference approach that strategically employs the base model for only the first critical timestep before transitioning to the efficient distilled model</li>
</ul>
</p>
<p>
Our approach not only restores but exceeds the diversity of the original base model while maintaining nearly the computational efficiency of distilled inference. We also demonstrate that control methods like Concept Sliders and LoRAs can be seamlessly transferred between base and distilled models.
</p>
</div><!--card-block-->
</div><!--card-->

</div><!--row-->
  
<div class="row">
<div class="col">
  
<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/intro.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 1: <b>Diversity Distillation:</b> (a) a base diffusion model is very slow but has good diversity (b) a distilled model is fast but sacrifices diversity (c) we show how the diversity of the base model can be distilled into the fast model by substituting the first timestamp. <b>Control Distillation:</b> (d) Control methods like Concept sliders can be transferred from a base model to distilled models, effectively distilling control.</figcaption>
</figure>

<h2>The Problem: Distilled Models Lose Diversity</h2>
<p>
Diffusion models have revolutionized text-to-image generation but require dozens or hundreds of sequential denoising steps, making them computationally expensive. Diffusion distillation techniques address this by modifying model weights to reduce required inference steps.
</p>
<p>
However, this efficiency comes at a critical cost: <b>mode collapse</b>, where different initial noise seeds produce visually similar outputs, creating a fundamental trade-off between computational efficiency and generation diversity.
</p>

<h2>Key Insight: Control Capabilities Are Preserved</h2>
<p>
Our analysis reveals a surprising property: distilled diffusion models maintain consistent concept representations with their base counterparts, despite the distillation procedure. We verify this through concept transfer experiments, where control mechanisms trained on base models can be seamlessly applied to distilled variants and vice versa.
</p>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 2: Control mechanisms like Concept Sliders, Custom Diffusion, and DreamBooth trained on base models can be transferred to all distilled models without any additional finetuning, demonstrating that concept representations are preserved through the distillation process.</figcaption>
</figure>

<h2>DT-Visualization: Understanding Diffusion Dynamics</h2>
<p>
To understand why diversity collapses during distillation despite preserved concept representations, we introduce <b>DT-Visualization</b> (Diffusion Target), a novel analysis technique that reveals what a diffusion model "thinks" the final image will be at any intermediate timestep.
</p>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 3: DT-Visualization reveals how models predict final outputs at intermediate steps. This image shows the diffusion target visualization process that extrapolates what the model is planning at each timestep.</figcaption>
</figure>

<h3>DT-Visualization for Debugging</h3>
<p>
DT-Visualization serves as a powerful debugging tool for investigating artifacts and inconsistencies in diffusion model outputs.
</p>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 4: DT-Visualization reveals generation inconsistencies. When prompted with "Image of dog and cat sitting on sofa," the model initially conceptualizes both animals but later discards one element in the final generation.</figcaption>
</figure>

<h3>DT-Visualization for Understanding Mode Collapse</h3>
<p>
Through DT-Visualization, we discover that the initial diffusion steps disproportionately determine structural composition and diversity, while subsequent steps primarily refine details.
</p>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 5: Comparison of standard diffusion visualization vs. DT-Visualization. Left: Standard visualization shows subtle differences between base and distilled models. Right: Our technique reveals that distilled models commit to final image structure in the first timestep, while base models gradually refine structure across multiple steps.</figcaption>
</figure>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 6: Measuring the DreamSim distance between intermediate DT-visualization and final image reveals that distilled models establish structural image composition within the initial diffusion step, whereas base models require approximately 30% of steps to achieve comparable structural definition.</figcaption>
</figure>

<h2>Diversity Distillation: A Hybrid Approach</h2>
<p>
Based on our insights from DT-Visualization, we introduce <b>Diversity Distillation</b>, a hybrid inference approach that strategically employs the base model for only the first critical timestep before transitioning to the distilled model for efficient completion of the generation process.
</p>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 7: Visual comparison of generation diversity. Each row shows three different generations (different random seeds) for the same prompt using: (left) base model, (middle) distilled model, and (right) our diversity distillation approach.</figcaption>
</figure>

<h2>Results</h2>
<p>
Our experimental results demonstrate that this hybrid approach not only restores the diversity lost during distillation but exceeds the diversity of the original base model while maintaining nearly the computational efficiency of distilled inference.
</p>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 8: Quantitative comparison showing FID scores and inference time. Our diversity distillation approach achieves better FID than both the base and distilled models while maintaining similar speed to distilled models.</figcaption>
</figure>

<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>Figure 9: Hyperparameter analysis of our method, showing the impact of guidance scale, number of timesteps, and computational trade-offs.</figcaption>
</figure>

<h2>How to cite</h2>

<p>The paper can be cited as follows.</p>

<div class="card">
<h3 class="card-header">bibliography</h3>
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Rohit Gandikota, David Bau. "<em>Distilling Diversity and Control in Diffusion Models.</em>"
</p>
</div>
<h3 class="card-header">bibtex</h3>
<div class="card-block">
<pre class="card-text clickselect">
@article{gandikota2025distilling,
  title={Distilling Diversity and Control in Diffusion Models},
  author={Rohit Gandikota and David Bau},
  journal={},
  year={2025}
}
</pre>
</div>
</div>
</p>

</div>
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://baulab.info/">About the Bau Lab</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
</script>
</html>